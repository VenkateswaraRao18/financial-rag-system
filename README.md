# ğŸ“Š Financial Report RAG System

An enterprise-grade Retrieval-Augmented Generation (RAG) system built to analyze financial reports (10-K filings) and answer analytical business questions using hybrid retrieval and large language models.

This project simulates an internal AI Financial Analyst used in enterprise environments.

---

## ğŸš€ Project Objective

Build a production-style RAG pipeline capable of:

- Processing large financial documents (10-K reports)
- Performing vector-based semantic retrieval
- Generating grounded answers using Gemini LLM
- Providing explainable and modular architecture
- Scaling toward hybrid retrieval and API deployment

---

## ğŸ— System Architecture

Financial PDFs (10-K Reports)
â†’
PDF Loader (PyPDF)
â†’
Sliding Window Chunking
â†’
SentenceTransformers Embeddings (MiniLM)
â†’
FAISS Vector Index (Dense Retrieval)
â†’
Top-K Relevant Chunks
â†’
Gemini LLM (Context-Grounded Generation)
â†’
Final Answer

---

## ğŸ” Core Components

### 1ï¸âƒ£ Document Ingestion

- Extracts text from financial PDFs
- Handles multi-page annual reports

### 2ï¸âƒ£ Chunking Strategy

- Sliding window chunking
- Overlap-based context preservation
- Optimized for long financial paragraphs

### 3ï¸âƒ£ Embeddings

- Model: `all-MiniLM-L6-v2`
- Lightweight and CPU-efficient
- Generates dense vector representations

### 4ï¸âƒ£ Vector Search

- FAISS (L2 similarity)
- Top-K semantic retrieval
- Efficient search over 900+ chunks

### 5ï¸âƒ£ LLM Generation

- Model: Gemini (Cloud-based)
- Prompt constrained to retrieved context
- Prevents hallucination outside report

---

## ğŸ§  Example Analytical Questions

- What were the main revenue drivers in 2024?
- What key risk factors were identified?
- Compare automotive revenue with energy segment performance.
- How does the company describe liquidity and debt obligations?

---

## ğŸ“¦ Tech Stack

- Python
- SentenceTransformers
- FAISS (CPU)
- Google Gemini API
- Modular Project Architecture
- VS Code Development Environment

---

## ğŸ† Engineering Highlights

- Modular folder structure
- Separation of ingestion, embeddings, retrieval, and generation
- Debug-friendly retrieval pipeline
- Source tracking for retrieved chunks
- Context-grounded prompting
- CPU-friendly architecture

---

## ğŸ“ˆ Current Performance

- ~900+ chunks indexed
- Sub-second retrieval time
- Accurate financial answer grounding
- No external hallucination observed during testing

---

## ğŸ”¥ Upcoming Enhancements

### ğŸ”¹ Hybrid Retrieval (BM25 + Dense)

Combine lexical + semantic search for improved recall.

### ğŸ”¹ Cross-Encoder Re-ranking

Transformer-based re-ranking of retrieved chunks.

### ğŸ”¹ FAISS Persistence

Save and reload index to avoid recomputation.

### ğŸ”¹ API Deployment

Expose system via FastAPI endpoint.

### ğŸ”¹ Evaluation Framework

Integrate RAGAS for:

- Faithfulness
- Answer relevancy
- Context precision

### ğŸ”¹ Monitoring

Add logging for:

- Retrieval latency
- Token usage
- Drift detection

---

## ğŸŒ Production Roadmap

This project is designed to evolve toward:

- Enterprise-scale knowledge assistant
- Internal AI financial research tool
- Scalable cloud deployment (AWS / GCP)
- Multi-document hybrid retrieval

---

## ğŸ“‚ Project Structure

financial-rag/

â”œâ”€â”€ data/

â”œâ”€â”€ ingestion/

â”œâ”€â”€ embeddings/

â”œâ”€â”€ retrieval/

â”œâ”€â”€ generation/

â”œâ”€â”€ app.py

â””â”€â”€ README.md

---

## ğŸ¯ Why This Project Matters

This implementation demonstrates:

- Applied NLP engineering
- System design thinking
- Production-level code organization
- Real-world business use case
- LLM integration in enterprise context

---

## ğŸ‘¨â€ğŸ’» Author

Built as part of advanced applied NLP and system design learning focused on product-based company standards.
